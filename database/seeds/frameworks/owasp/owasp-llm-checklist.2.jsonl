{"page":1,"tags":["Adversarial Risk"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Adversarial Risk\n\nScrutinize how competitors are investing in artificial intelligence. Although there are risks in AI\n\nadoption, there are also business benefits that may impact future market positions.\n\nInvestigate the impact of current controls, such as password resets, which use voice\n\nrecognition which may no longer provide the appropriate defensive security from new GenAI\n\nenhanced attacks.\n\nUpdate the Incident Response Plan and playbooks for GenAI enhanced attacks and AIML\n\nspecific incidents."}
{"page":1,"tags":["Threat Modeling"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Threat Modeling\n\nHow will attackers accelerate exploit attacks against the organization, employees, executives,\n\nor users? Organizations should anticipate \"hyper-personalized\" attacks at scale using\n\nGenerative AI. LLM-assisted Spear Phishing attacks are now exponentially more effective,\n\ntargeted, and weaponized for an attack.\n\nHow could GenAI be used for attacks on the business's customers or clients through spoofing or GenAI generated content?\n\nCan the business detect and neutralize harmful or malicious inputs or queries to LLM solutions?\n\nCan the business safeguard connections with existing systems and databases with secure integrations at all LLM trust boundaries?\n\nDoes the business have insider threat mitigation to prevent misuse by authorized users?\n\nCan the business prevent unauthorized access to proprietary models or data to protect Intellectual Property?\n\nCan the business prevent the generation of harmful or inappropriate content with automated content filtering?"}
{"page":1,"tags":["AI Asset Inventory"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# AI Asset Inventory\n\nCatalog existing AI services, tools, and owners. Designate a tag in asset management for specific inventory.\n\nInclude AI components in the Software Bill of Material (SBOM), a comprehensive list of all the software components, dependencies, and metadata associated with applications.\n\nCatalog AI data sources and the sensitivity of the data (protected, confidential, public)\n\nEstablish if pen testing or red teaming of deployed AI solutions is required to determine the current attack surface risk.\n\nCreate an AI solution onboarding process.\n\nEnsure skilled IT admin staff is available either internally or externally, following SBoM requirements."}
{"page":1,"tags":["AI Security and Privacy Training"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# AI Security and Privacy Training\n\nActively engage with employees to understand and address concerns with planned LLM initiatives.\n\nEstablish a culture of open, and transparent communication on the organization's use of predictive or generative AI within the organization process, systems, employee management and support, and customer engagements and how its use is governed, managed, and risks addressed.\n\nTrain all users on ethics, responsibility, and legal issues such as warranty, license, and copyright.\n\nUpdate security awareness training to include GenAI related threats. Voice cloning and image cloning, as well as in anticipation of increased spear phishing attacks\n\nAny adopted GenAI solutions should include training for both DevOps and cybersecurity for the deployment pipeline to ensure AI safety and security assurances."}
{"page":1,"tags":["Establish Business Cases"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Establish Business Cases\n\nSolid business cases are essential to determining the business value of any proposed AI solution, balancing risk and bene fits, and evaluating and testing return on investment. There are an enormous number of potential use cases; a few examples are provided."}
{"page":1,"tags":["Governance"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Governance\n\nEstablish the organization's AI RACI chart (who is responsible, who is accountable, who should be consulted, and who should be informed)\n\nDocument and assign AI risk, risk assessments, and governance responsibility within the organization.\n\nEstablish data management policies, including technical enforcement, regarding data classification and usage limitations. Models should only leverage data classified for the minimum access level of any user of the system. For example, update the data protection policy to emphasize not to input protected or confidential data into non business-managed tools.\n\nCreate an AI Policy supported by established policy (e.g., standard of good conduct, data protection, software use)\n\nPublish an acceptable use matrix for various generative AI tools for employees to use.\n\nDocument the sources and management of any data that the organization uses from the generative LLM models."}
{"page":1,"tags":["Legal"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Legal\n\nConfirm product warranties are clear in the product development stream to assign who is responsible for product warranties with AI.\n\nReview and update existing terms and conditions for any GenAI considerations.\n\nReview AI EULA agreements. End-user license agreements for GenAI platforms are very different in how they handle user prompts, output rights and ownership, data privacy, compliance, liability, privacy, and limits on how output can be used.\n\nOrganizations EULA for customers, Modify end-user agreements to prevent the organization from incurring liabilities related to plagiarism, bias propagation, or intellectual property infringement through AI-generated content.\n\nReview existing AI-assisted tools used for code development. A chatbot's ability to write code can threaten a company's ownership rights to its product if a chatbot is used to generate code for the product. For example, it could call into question the status and protection of the generated content and who holds the right to use the generated content.\n\nReview any risks to intellectual property. Intellectual property generated by a chatbot could be in jeopardy if improperly obtained data was used during the generative process, which is subject to copyright, trademark, or patent protection. If AI products use infringing material, it creates a risk for the outputs of the AI, which may result in intellectual property infringement.\n\nReview any contracts with indemni fication provisions. Indemni fication clauses try to put the responsibility for an event that leads to liability on the person who was more at fault for it or who had the best chance of stopping it. Establish guardrails to determine whether the provider of the AI or its user caused the event, giving rise to liability.\n\nReview liability for potential injury and property damage caused by AI systems.\n\nReview insurance coverage. Traditional (D&O) liability and commercial general liability insurance policies are likely insufficient to fully protect AI use.\n\nIdentify any copyright issues. Human authorship is required for copyright. An organization may also be liable for plagiarism, propagation of bias, or intellectual property infringement if LLM tools are misused.\n\nEnsure agreements are in place for contractors and appropriate use of AI for any development or provided services.\n\nRestrict or prohibit the use of generative AI tools for employees or contractors where enforceable rights may be an issue or where there are IP infringement concerns.\n\nAssess and AI solutions used for employee management or hiring could result in disparate treatment claims or disparate impact claims.\n\nMake sure the AI solutions do not collect or share sensitive information without proper consent or authorization."}
{"page":1,"tags":["Regulatory"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Regulatory\n\nDetermine Country, State, or other Government specific AI compliance requirements.\n\nDetermine compliance requirements for restricting electronic monitoring of employees and employment-related automated decision systems (Vermont, California, Maryland, New York, New Jersey)\n\nDetermine compliance requirements for consent for facial recognition and the AI video analysis required (Illinois, Maryland, Washington, Vermont)\n\nConfirm the vendor's compliance with applicable AI laws and best practices.\n\nReview any AI tools in use or being considered for employee hiring or management.\n\nAsk and document any products using AI during the hiring process. Ask how the model was trained, and how it is monitored, and track any corrections made to avoid discrimination and bias.\n\nAsk and document what accommodation options are included.\n\nAsk how the vendor or tool stores and deletes data and regulates the use of facial recognition and video analysis tools during pre-employment.\n\nAsk and document whether the vendor collects confidential data.\n\nReview other organization-specific regulatory requirements with AI that may raise compliance issues. The Employee Retirement Income Security Act of 1974, for instance, has fiduciary duty requirements for retirement plans that a chatbot might not be able to meet."}
{"page":1,"tags":["Using or Implementing Large Language Model Solutions"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Using or Implementing Large Language Model Solutions\n\nThreat Model LLM components and architecture trust boundaries.\n\nData Security, verify how data is classi fied and protected based on sensitivity, including personal and proprietary business data. (How are user permissions managed, and what safeguards are in place?)\n\nAccess Control, implement least privilege access controls and implement defense-in-depth measures\n\nTraining Pipeline Security, require rigorous control around training data governance, pipelines, models, and algorithms.\n\nInput and Output Security, evaluate input validation methods, as well as how outputs are filtered, sanitized, and approved.\n\nMonitoring and Response, map workflows, monitoring, and responses to understand automation, logging, and auditing. Con firm audit records are secure.\n\nInclude application testing, source code review, vulnerability assessments, and red teaming in the production release process.\n\nCheck for existing vulnerabilities in the LLM model or supply chain.\n\nLook into the effects of threats and attacks on LLM solutions, such as prompt injection, the release of sensitive information, and process manipulation.\n\nInvestigate the impact of attacks and threats to LLM models, including model poisoning, improper data handling, supply chain attacks, and model theft.\n\nSupply Chain Security, request third-party audits, penetration testing, and code reviews for third-party providers. (both initially and on an ongoing basis)\n\nInfrastructure Security, ask how often a vendor performs resilience testing? What are their SLAs in terms of availability, scalability, and performance?\n\nUpdate incident response playbooks and include an LLM incident in tabletop exercises.\n\nIdentify or expand metrics to benchmark generative cybersecurity AI against other approaches to measure expected productivity improvements."}
{"page":1,"tags":["Testing, Evaluation, Veri fication, and Validation (TEVV)"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Testing, Evaluation, Veri fication, and Validation (TEVV)\n\nEstablish continuous testing, evaluation, verification, and validation throughout the AI model lifecycle.\n\nProvide regular executive metrics and updates on AI Model functionality, security, reliability, and robustness."}
{"page":1,"tags":["Model Cards and Risk Cards"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# Model Cards and Risk Cards\n\nModel details : Basic information about the model, i.e., name, version, and type ( neural network, decision tree, etc.), and the intended use case.\n\nModel architecture : Includes a description of the structure of the model, such as the number and type of layers, activation functions, and other key architectural choices.\n\nTraining data and methodology : Information about the data used to train the model, such as the size of the dataset, the data sources, and any preprocessing or data augmentation techniques used. It also includes details about the training methodology, such as the optimizer used, the loss function, and any hyperparameters that were tuned.\n\nPerformance metrics : Information about the model's performance on various metrics, such as accuracy, precision, recall, and F \/one.pnum score. It may also include information about how the model performs on different subsets of the data.\n\nPotential biases and limitations : Lists potential biases or limitations of the model, such as imbalanced training data, over fitting, or biases in the model's predictions. It may also include information about the model's limitations, such as its ability to generalize to new data or its suitability for certain use cases.\n\nResponsible AI considerations : Any ethical or responsible AI considerations related to the model, such as privacy concerns, fairness, and transparency, or potential societal impacts of the model's use. It may also include recommendations for further testing, validation, or monitoring of the model.\n\nReview a model's model card\n\nReview risk card if available\n\nEstablish a process to track and maintain model cards for any deployed model including models used through a third party."}
{"page":1,"tags":["RAG: Large Language Model Optimization"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# RAG: Large Language Model Optimization\n\nRetrieval-Augmented Generation RAG has evolved as a more effective way of optimizing and augmenting the capabilities of large language models by retrieving pertinent data from up to date available knowledge sources. RAG can be customized for speci fic domains, optimizing the retrieval of domain-speci fic information and tailoring the generation process to the nuances of specialized fields. RAG is seen as a more ef ficient and transparent method for LLM optimization, particularly for problems where labeled data is limited or expensive to collect. One of the primary advantages of RAG is its support for continuous learning since new information can be continually updated at the retrieval stage."}
{"page":1,"tags":["AI Red Teaming"],"text":"**Provider.** OWASP\n**Title.** LLM AI Cybersecurity & Governance Checklist\n**Description.** This checklist is intended to help technology and business leaders quickly understand the risks and bene ts of using LLM, allowing them to focus on developing a comprehensive list of critical areas and tasks needed to defend and protect the organization as they develop a Large Language Model strategy.\n\n# AI Red Teaming\n\nIncorporate Red Team testing as a standard practice for AI Models and applications."}
